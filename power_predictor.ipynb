{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06284050",
   "metadata": {},
   "source": [
    "# Power Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d355fed3",
   "metadata": {},
   "source": [
    "Standard is a format of the trading card game Magic: the Gathering in which players are only allowed to use cards from the past few years of set releases. Because of the limited card pool, new additions to the format via new set releases often have a dramatic effect, but it can be hard to predict what cards will be powerful when they release. \n",
    "\n",
    "This project seeks to rate Magic: the Gathering cards for power level in the current Standard format on a scale from 1-5, with 1 being completely unplayable and irrelevant, and 5 being format warping and broken. In order to do this effectively, I used two methods, and compared them to find the best approach. \n",
    "\n",
    "The first was to use OpenAI's API and make API calls to gpt-4-turbo. When given a card name, this module will fetch the relevant card data from the Scryfall API, including Oracle text, mana cost, and types. The data is then given to the API with a carefully engineered prompt, and it responds with a rating and rational for that rating.\n",
    "\n",
    "The second approach was to download a pretrained LLM from huggingface and then fine-tune it on a list of standard-legal Magic: the Gathering cards each paired with a power rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872540f",
   "metadata": {},
   "source": [
    "#### Scryfall fetch code\n",
    "\n",
    "Method to fetch card data from scryfall. It is stored in a dictionary and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b9ce177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_card_info(card_name):\n",
    "        \"\"\"\n",
    "        Fetch Magic: The Gathering card information from Scryfall API\n",
    "        \n",
    "        Args:\n",
    "            card_name: Name of the MTG card to search for\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with card information or None if card not found\n",
    "        \"\"\"\n",
    "        # URL encode the card name for the API request\n",
    "        url = f\"https://api.scryfall.com/cards/named?exact={card_name}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url).json()\n",
    "            \n",
    "            # Check if the request was successful\n",
    "            if response:\n",
    "                card_data = response\n",
    "                \n",
    "                # Extract the requested information\n",
    "                card_info = {\n",
    "                    'name': card_data.get('name'),\n",
    "                    'mana_cost': card_data.get('mana_cost'),\n",
    "                    'types': card_data.get('type_line'),\n",
    "                    'oracle_text': card_data.get('oracle_text'),\n",
    "                    'power': card_data.get('power'),\n",
    "                    'toughness': card_data.get('toughness'),\n",
    "                    'loyalty': card_data.get('loyalty')\n",
    "                }\n",
    "                \n",
    "                return card_info\n",
    "            else:\n",
    "                print(f\"Error: Could not find card named '{card_name}'\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6fee89",
   "metadata": {},
   "source": [
    "## API Call\n",
    "\n",
    "This section contains the code and prompts for the API Call section of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc829a4",
   "metadata": {},
   "source": [
    "### Imports\n",
    "* requests: easy get requests from Scryfall API\n",
    "* openai: API library\n",
    "* Markdown, display: Library for displaying markdown output from the API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fee49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02678ce5",
   "metadata": {},
   "source": [
    "#### Get card info\n",
    "This method retrieves relevant information about cards from Scryfall, which is a database containing Magic: the Gathering cards and the information about them. It stores the information in a map (card_info), which links the information to appropriate names and returns the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c96f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_info(card_name):\n",
    "        \"\"\"\n",
    "        Fetch Magic: The Gathering card information from Scryfall API\n",
    "        \n",
    "        Args:\n",
    "            card_name: Name of the MTG card to search for\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with card information or None if card not found\n",
    "        \"\"\"\n",
    "        # URL encode the card name for the API request\n",
    "        url = f\"https://api.scryfall.com/cards/named?exact={card_name}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url).json()\n",
    "            \n",
    "            # Check if the request was successful\n",
    "            if response:\n",
    "                card_data = response\n",
    "                \n",
    "                # Extract the requested information\n",
    "                card_info = {\n",
    "                    'image_uris': card_data.get('image_uris'),\n",
    "                    'name': card_data.get('name'),\n",
    "                    'mana_cost': card_data.get('mana_cost'),\n",
    "                    'types': card_data.get('type_line'),\n",
    "                    'oracle_text': card_data.get('oracle_text'),\n",
    "                    'power': card_data.get('power'),\n",
    "                    'toughness': card_data.get('toughness'),\n",
    "                    'loyalty': card_data.get('loyalty')\n",
    "                }\n",
    "                \n",
    "                return card_info\n",
    "            else:\n",
    "                print(f\"Error: Could not find card named '{card_name}'\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93e233",
   "metadata": {},
   "source": [
    "#### System Prompt\n",
    "\n",
    "This is the system prompt, which is given to the API before being prompted with a card. First, it outlines the task, which is to rate a card on a scale from 1-5 in the standard format, which is outlined and briefly described. Then each number on the scale is given a definition, and it's meaning is outlined. The model is told what the analysis of the score should include, and then there are 5 examples, 1 for each tier of power. This gives the model the ability to learn in-context, and provides a baseline for the model to compare cards it is asked to rate to. I attempted to choose a diverse set of cards to use as examples so that the model would have information about all types of cards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3addd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a Magic: The Gathering expert specializing in evaluating cards for Standard format play.\n",
    "    The best standard decks in the foramt are highly value centered and full of removal and powerful threats.\n",
    "    Analyze the provided card based on its mana cost, types, oracle text, and power/toughness if applicable.\n",
    "    Rate the card on a scale of 1-5 where:\n",
    "    \n",
    "    1: Unplayable in every situation, and outclassed by other cards\n",
    "    2: Of only average strength. Playable in niche archetypes or for specific sideboard uses\n",
    "    3: Strong cards that can be played in a variety of decks, but mainly as a supporting card\n",
    "    4: Exceptionally strong cards that inspire deck archetypes and provide lots of value on their own\n",
    "    5: Broken and format-warping card than defines the metagame\n",
    "    \n",
    "    Your analysis should include:\n",
    "    1. Power Rating (1-5)\n",
    "    2. Strengths of the card\n",
    "    3. Weaknesses or limitations\n",
    "    \n",
    "    Here is an example of a 1: \n",
    "    Card Name: \"Air Marshal\"\n",
    "    Mana Cost: 1U\n",
    "    Types: Creature - Human Soldier\n",
    "    Oracle Text: 3: Target Soldier gains flying until end of turn.\n",
    "    Power: 2\n",
    "    Toughness: 1\n",
    "    \n",
    "    This card provides a mediocre body for its cost, and the cost of 3 mana to give a creature flying is far too high for the effect.\n",
    "    It is outclassed by many other cards in the format and does not provide enough value to be worth playing.\n",
    "    \n",
    "    Here is an example of a 2:\n",
    "    Card Name: \"Abrade\"\n",
    "    Mana Cost: 1R\n",
    "    Types: Instant\n",
    "    Oracle text: Choose one - Abrade deals 3 damage to target creature; or destroy target artifact.\n",
    "    Power: N/A\n",
    "    Toughness: N/A\n",
    "    This card provides decent utility, but at 2 mana it doesn't provide enough value to be worth playing in most decks.\n",
    "    \n",
    "    Here is an example of a 3:\n",
    "    Card Name: Amalia Benavides Aguirre\n",
    "    Mana Cost: WB\n",
    "    Types: Legendary Creature - Vampire Scout\n",
    "    Oracle text: Ward - Pay 3 life. Whenever you gain life, Amalia Benavides Aguirre explores. Then destroy all other creatures if its power is exactly 20. (To have this creature explore, reveal the top card of your library. Put that card into your hand if it is a land. Otherwise, put a +1/+1 counter on this creature, then put the card back or put it into your graveyard.)\n",
    "    Power: 2\n",
    "    Toughness: 2\n",
    "    This card provides excellent value for life gain deck via growing power and toughness and lots of card selection. Becuase of this, it is a powerful addition to decks that gain life incrementally.\n",
    "    \n",
    "    Here is an example of a 4: \n",
    "    Card Name: \"Overlord of the Hauntwoods\"\n",
    "    Mana Cost: 3GG\n",
    "    Types: Enchantment Creature - Avatar Horror\n",
    "    Oracle Text: Impending 4—1GreenGreen (If you cast this spell for its impending cost, it enters with four time counters and isn't a creature until the last is removed. At the beginning of your end step, remove a time counter from it.) Whenever this permanent enters or attacks, create a tapped colorless land token named Everywhere that is every basic land type.\n",
    "    This card provides immense value for ramp decks and domain decks via its ability to create a land token that is every basic land type. Furthermore, it is flexible in that it can be played for full price as a creature, or early for its impending cost.\n",
    "    This card is very powerful, and finds its way into many decks.\n",
    "    \n",
    "    Here is an example of a 5:\n",
    "    Card Name: \"Up the Beanstalk\"\n",
    "    Mana Cost: 1G\n",
    "    Types: Enchantment\n",
    "    Oracle text: When Up the Beanstalk enters the battlefield and whenever you cast a spell with mana value 5 or greater, draw a card.\n",
    "    Power: N/A\n",
    "    Toughness: N/A\n",
    "    \n",
    "    This card provides immediate value upon entering via drawing a card, and provides powerful repeated value throughout the game.\n",
    "    Furthermore, because of synergies with other strong cards in the format, it is very easy to trigger the card draw effect.\n",
    "    This card is the reason many of the best decks exist, and is a format-defining card.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0fc60",
   "metadata": {},
   "source": [
    "#### OpenAI API key\n",
    "\n",
    "Insert OpenAI API key here to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923bfd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd74305",
   "metadata": {},
   "source": [
    "#### API Call\n",
    "\n",
    "This method calls the LLM API. It is passed the map of card information, and plugs it into the user prompt to elicit a response. 1000 max token is chosen because as this task can be quite complicated, sometimes extensive analysis is required. A temperature of 0.2 ensures that the model does not provide inaccurate ratings that were not the most likely option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d7e94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_card(card_info):\n",
    "    try:\n",
    "        client = openai.OpenAI(api_key=API_KEY)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Please analyze this Magic: The Gathering card:\\n\\nName: {card_info['name']}\\nMana Cost: {card_info['mana_cost']}\\nTypes: {card_info['types']}\\nOracle Text: {card_info['oracle_text']}\\nPower/Toughness: {card_info['power']}/{card_info['toughness']}\\nLoyalty: {card_info['loyalty']}\\n\\n\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658144bc",
   "metadata": {},
   "source": [
    "#### Driver code\n",
    "\n",
    "This cell calls each method defined above and prints the LLM's response, which is given in Markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0f4d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up the Beanstalk\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Power Rating: 5\n",
       "\n",
       "Strengths of the card:\n",
       "1. **Immediate Value**: \"Up the Beanstalk\" provides immediate value upon entering the battlefield by drawing a card. This helps mitigate the cost of playing the enchantment by replacing itself in your hand, ensuring that you do not lose card advantage.\n",
       "2. **Recurring Value**: The ability to draw a card whenever you cast a spell with mana value 5 or greater can lead to significant card advantage over the course of a game. This is particularly strong in formats where higher-cost spells are prevalent and impactful.\n",
       "3. **Deck Synergy**: This card fits well into decks that naturally want to play larger spells, such as ramp decks or control decks that stabilize and then play high-impact spells. It synergizes with the game plan of casting big, game-changing spells by rewarding you with additional card draw.\n",
       "4. **Low Mana Cost**: At only 2 mana, this enchantment is very easy to incorporate into a variety of game plans without setting back your development. Its low cost also makes it a minimal risk investment in terms of tempo.\n",
       "\n",
       "Weaknesses or limitations:\n",
       "1. **Dependency on Deck Composition**: The card's effectiveness is highly dependent on having a sufficient number of spells with mana value 5 or greater in your deck. In decks without these higher-cost spells, its value diminishes significantly.\n",
       "2. **No Immediate Impact on the Board**: While it provides card advantage, \"Up the Beanstalk\" does not affect the board state directly when played. This could be a disadvantage in very aggressive metagames where tempo and board presence are more critical than card advantage.\n",
       "\n",
       "Overall, \"Up the Beanstalk\" is a powerful enchantment that can define the structure and strategy of the decks it's included in. Its ability to consistently generate card advantage in the right deck makes it a format-defining card, meriting a rating of 5. It encourages and rewards building around a specific type of deck, influencing the metagame significantly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abrade\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Power Rating: 4\n",
       "\n",
       "Strengths of the card:\n",
       "1. **Flexibility**: Abrade's primary strength lies in its flexibility. The ability to choose between dealing 3 damage to a creature or destroying an artifact makes it highly versatile and valuable in a variety of game situations. This adaptability allows it to be effective in both the early and late game, handling threats or key utility artifacts.\n",
       "2. **Cost Efficiency**: At a cost of only {1}{R}, Abrade is very mana-efficient. This low cost enables players to remain reactive and flexible with their mana, potentially casting other spells in the same turn.\n",
       "3. **Instant Speed**: Being an instant significantly enhances Abrade's utility, allowing players to use it as a combat trick or in response to an opponent's actions during their turn. This can disrupt opponent strategies and provide surprise interactions that can swing the game.\n",
       "\n",
       "Weaknesses or limitations:\n",
       "1. **Damage Limitation**: The damage cap of 3 means that Abrade cannot deal with larger creatures that are common in many Standard formats. This limits its effectiveness against some of the format's bigger threats.\n",
       "2. **No Player or Planeswalker Targeting**: Abrade is limited to targeting creatures and artifacts only. It cannot target players or planeswalkers, which restricts its utility compared to some other removal spells that offer broader targeting options.\n",
       "\n",
       "Overall, Abrade's strengths in flexibility and cost efficiency make it an exceptionally strong card that can fit into multiple deck archetypes, especially in environments where artifacts are prevalent or where efficient creature removal is necessary. Its limitations are minor compared to the broad utility it offers, making it a staple in many Standard decks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abzan Monument\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Power Rating: 3**\n",
       "\n",
       "**Strengths of the card:**\n",
       "1. **Mana Efficiency and Ramp:** Abzan Monument has a low initial mana cost of {2}, making it an accessible early-game play. Its ability to fetch a basic Plains, Swamp, or Forest upon entering the battlefield aids in mana fixing and slight ramping, which is crucial in a three-color deck.\n",
       "2. **Flexibility in Token Generation:** The second ability to create an X/X white Spirit creature token, where X is the greatest toughness among creatures you control, can be a significant late-game advantage. This ability allows for the creation of potentially large blockers or attackers, depending on the board state.\n",
       "3. **Synergy with Creature-Based Strategies:** In decks that focus on creatures with high toughness, this artifact can consistently generate large tokens, making it a valuable asset in defensive or attrition strategies.\n",
       "\n",
       "**Weaknesses or Limitations:**\n",
       "1. **Sorcery Speed Restriction:** The activation of the token-generating ability only at sorcery speed limits its flexibility, particularly in reactive or instant-speed centered strategies. This restriction prevents it from being used as a surprise blocker or in response to removal, which could be a significant downside in some tactical situations.\n",
       "2. **Dependency on Board State:** The value of the token generated depends heavily on the presence of creatures with high toughness. In scenarios where the board is wiped or the player is unable to establish a substantial creature presence, this artifact's utility diminishes greatly.\n",
       "3. **One-Time Use of the Second Ability:** The requirement to sacrifice Abzan Monument to use its token-generating ability means it's a one-time effect. This can be a considerable limitation if the game extends and continuous value generation is necessary.\n",
       "\n",
       "**Overall Evaluation:**\n",
       "Abzan Monument is a strong card in decks that can utilize both its mana-fixing early game and its potential to create large creature tokens in the mid to late game. It fits well into Abzan-colored decks that focus on creature-based strategies, particularly those that can maintain a board state with creatures of high toughness. However, its limitations in flexibility and dependency on the board state prevent it from being a universally powerful card in all types of decks, thus earning it a rating of 3."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monastery Swiftspear\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Power Rating: 4\n",
       "\n",
       "Strengths of the card:\n",
       "1. **Low Mana Cost**: Monastery Swiftspear costs only a single red mana, making it extremely easy to deploy early in the game. This low cost also allows for multiple spells to be played in the same turn, maximizing its prowess ability.\n",
       "2. **Haste**: The haste ability allows Monastery Swiftspear to attack immediately, providing immediate impact on the game by pressuring the opponent's life total from the very first turn it is played.\n",
       "3. **Prowess**: This ability is particularly strong in decks that utilize a high number of noncreature spells (such as instants and sorceries). Each spell cast not only furthers the player's game plan but also temporarily boosts Monastery Swiftspear, potentially increasing the damage output significantly.\n",
       "4. **Flexibility**: Its inclusion in a variety of aggressive and spell-heavy decks (like Burn, Red Deck Wins, or Izzet Spells) showcases its versatility and ability to fit into multiple strategies effectively.\n",
       "\n",
       "Weaknesses or limitations:\n",
       "1. **Fragility**: With a base toughness of 2, Monastery Swiftspear is vulnerable to many of the commonly played removal spells in the format, such as Shock or Stomp. This can sometimes lead to unfavorable trades or easy removal by the opponent.\n",
       "2. **Dependence on Noncreature Spells**: To maximize the value of Monastery Swiftspear, a deck needs to be built with a sufficient number of noncreature spells. In decks not designed with this synergy in mind, its effectiveness can be significantly diminished.\n",
       "\n",
       "Overall, Monastery Swiftspear is an exceptionally strong card in the right deck, capable of applying early pressure and scaling its threat level as the game progresses. Its ability to inspire aggressive red-based deck archetypes and its proven track record in competitive play across multiple formats solidify its high rating."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "card_to_analyze1 = \"Up the Beanstalk\"\n",
    "info1 = get_card_info(card_to_analyze1)\n",
    "rating1 = analyze_card(info1)\n",
    "print(card_to_analyze1)\n",
    "display(Markdown(rating1))\n",
    "\n",
    "card_to_analyze2 = \"Abrade\"\n",
    "info2 = get_card_info(card_to_analyze2)\n",
    "rating2 = analyze_card(info2)\n",
    "print(card_to_analyze2)\n",
    "display(Markdown(rating2))\n",
    "\n",
    "card_to_analyze3 = \"Abzan Monument\"\n",
    "info3 = get_card_info(card_to_analyze3)\n",
    "rating3 = analyze_card(info3)\n",
    "print(card_to_analyze3)\n",
    "display(Markdown(rating3))\n",
    "\n",
    "card_to_analyze4 = \"Monastery Swiftspear\"\n",
    "info4 = get_card_info(card_to_analyze4)\n",
    "rating4 = analyze_card(info4)\n",
    "print(card_to_analyze4)\n",
    "display(Markdown(rating4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca47c805",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Overall, the model performs quite well with most cards. It gives a reasonable answer that agrees with my analysis and provides quality analysis of why the card is in the spot that it chose.\n",
    "\n",
    "Problems: The model often gives cards a rating higher than what is correct. For example, as seen in the above examples, it rates Abrade a 4 and Abzan Monument a 3. I would rate them both as 2, being playable in specific decks. The model tends to give cards that have flexible uses hgiher scores. Abrade has two modes that can be chosen, and Abzan Monument has a mode that can be activated in the late game to provide a powerful creature. It references this flexibility in it's analysis as one of the reasons for it's rating. This could potentially be solved with more additions to the prompt.\n",
    "\n",
    "In conclusion, this model performs adequately in most circumstances, especially on simpler cards. It tends to over-rate cards, giving them scores roughly 1 point higher than is accurate. However, the analysis given is very good. The model identifies the strengths and weaknesses of each card quite effectively. One problem with the model is the lack of awareness of other cards in the format. An important aspect in whether or not a card is good in Standard is the power of other cards that synergize with it. Since this approach is unable to know what is in standard at the current moment, it can't take this into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306df7b",
   "metadata": {},
   "source": [
    "## Fine Tuned LLM\n",
    "\n",
    "This section contains the code and output for the fine-tuned distilbert model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8829c3",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "* Pandas, datasets: data tools\n",
    "* predictor, transformers, peft, torch: LLM and training tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa5dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import predictor\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203531b",
   "metadata": {},
   "source": [
    "#### Login to Huggingface\n",
    "\n",
    "Provide a huggingface key to load distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9155a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478cfccc50b7454e8e4e50cc3ca85c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa182ab",
   "metadata": {},
   "source": [
    "#### Model Hyperparameters\n",
    "\n",
    "Relevant decisions:\n",
    "* Model: distilbert-base-uncased chosen for size and classification prowess\n",
    "* Learning rate: low learning rate chosen to help avoid overfitting on the small dataset\n",
    "* Batch size: small batch size to help avoid overfitting\n",
    "* Low epoch number for the same reason as above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db3a554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring model...\n"
     ]
    }
   ],
   "source": [
    "print(\"configuring model...\")\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
    "OUTPUT_DIR = \"./mtg_rating_model\"\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0.05\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 5\n",
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8cc992",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "This dataset is 100 cards along with ratings chosen by me based on my experience with the game and also upon the MTG golfish meta page (https://www.mtggoldfish.com/metagame/standard/full#paper). The cards were semi-randomly chosen from all the cards available in the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddb15b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = [\n",
    "        \"Adventuring Gear\",\n",
    "        \"Basilisk Collar\",\n",
    "        \"Bloodthorn Flail\",\n",
    "        \"Carnelian Orb of Dragonkind\",\n",
    "        \"Carrot Cake\",\n",
    "        \"Cori-Steel Cutter\",\n",
    "        \"Gilded Lotus\",\n",
    "        \"Golden Argosy\",\n",
    "        \"Monument to Endurance\",\n",
    "        \"Perilous Snare\",\n",
    "        \"Racers' Scoreboard\",\n",
    "        \"Rope\",\n",
    "        \"Runaway Boulder\",\n",
    "        \"Abhorrent Oculus\",\n",
    "        \"Ajani's Pridemate\",\n",
    "        \"Ash, Party Crasher\",\n",
    "        \"Ball Lightning\",\n",
    "        \"Beza, the Bounding Spring\",\n",
    "        \"Bloodghast\",\n",
    "        \"Boulderborn Dragon\",\n",
    "        \"Brightblade Stoat\",\n",
    "        \"Defiler of Vigor\",\n",
    "        \"Diregraf Ghoul\",\n",
    "        \"Edgewall Pack\",\n",
    "        \"Elvish Archdruid\",\n",
    "        \"Essence Channeler\",\n",
    "        \"Evolved Sleeper\",\n",
    "        \"Fang Guardian\",\n",
    "        \"Fangkeeper's Familiar\",\n",
    "        \"Friendly Teddy\",\n",
    "        \"Fynn, the Fangbearer\",\n",
    "        \"Greedy Freebooter\",\n",
    "        \"Halo-Charged Skaab\",\n",
    "        \"Haughty Djinn\",\n",
    "        \"Heartfire Hero\",\n",
    "        \"Hinterland Sanctifier\",\n",
    "        \"Ingenious Leonin\",\n",
    "        \"Iridescent Vinelasher\",\n",
    "        \"Jolly Gerbils\",\n",
    "        \"Kiora, the Rising Tide\",\n",
    "        \"Knight-Errant of Eos\",\n",
    "        \"Kraul Whipcracker\",\n",
    "        \"Llanowar Elves\",\n",
    "        \"Manifold Mouse\",\n",
    "        \"Mintstrosity\",\n",
    "        \"Nurturing Pixie\",\n",
    "        \"Overlord of the Hauntwoods\",\n",
    "        \"Overlord of the Boilerbilges\",\n",
    "        \"Pride of the Road\",\n",
    "        \"Rankle and Torbran\",\n",
    "        \"Savage Ventmaw\",\n",
    "        \"Savannah Lions\",\n",
    "        \"Screaming Nemesis\",\n",
    "        \"Severance Priest\",\n",
    "        \"Sire of Seven Deaths\",\n",
    "        \"Skirmish Rhino\",\n",
    "        \"Spiteful Hexmage\",\n",
    "        \"Tangled Colony\",\n",
    "        \"Up the Beanstalk\",\n",
    "        \"Caretaker's Talent\",\n",
    "        \"Colossification\",\n",
    "        \"Disturbing Mirth\",\n",
    "        \"Leyline of Resonance\",\n",
    "        \"Lost in the Maze\",\n",
    "        \"Nahiri's Resolve\",\n",
    "        \"Nowhere to Run\",\n",
    "        \"Phyrexian Arena\",\n",
    "        \"Tribute to the World Tree\",\n",
    "        \"Monstrous Rage\",\n",
    "        \"Abrade\",\n",
    "        \"Aetherize\",\n",
    "        \"Bite Down\",\n",
    "        \"Flame Lash\",\n",
    "        \"Get Out\",\n",
    "        \"Get Lost\",\n",
    "        \"This Town Ain't Big Enough\",\n",
    "        \"Negate\",\n",
    "        \"On the Job\",\n",
    "        \"Opt\",\n",
    "        \"Rat Out\",\n",
    "        \"Refute\",\n",
    "        \"Ride's End\",\n",
    "        \"Slick Sequence\",\n",
    "        \"Steer Clear\",\n",
    "        \"Torch the Tower\",\n",
    "        \"Abuelo's Awakening\",\n",
    "        \"Boltwave\",\n",
    "        \"Captain's Call\",\n",
    "        \"Deathmark\",\n",
    "        \"Excavation Explosion\",\n",
    "        \"Exorcise\",\n",
    "        \"Feed the Swarm\",\n",
    "        \"Jailbreak Scheme\",\n",
    "        \"Lunar Insight\",\n",
    "        \"Maelstrom Pulse\",\n",
    "        \"Pyroclasm\",\n",
    "        \"Rankle's Prank\",\n",
    "        \"Zombify\",\n",
    "        \"Slime Against Humanity\",\n",
    "        \"Sunfall\"\n",
    "    ]\n",
    "\n",
    "ratings = [1, 2, 1, 2, 3, 4, 2, 2, 4, 3, 1, 2, 1, 4, 2, 2, 2, 4, 3, 1, 2, 3, 2, 2, 3, 3, 2, 1, 3, 1, 3, 3, 2, 3, 4, 3, 1, 3, 1, 3, 4, 2, 4, 3, 2, 3, 3, 4, 1, 2, 2, 2, 3, 2, 2, 3, 2, 2, 4, 1, 3, 4, 1, 1, 3, 3, 3, 5, 2, 3, 2, 1, 3, 3, 5, 3, 1, 3, 2, 2, 3, 2, 2, 3, 3, 2, 3, 2, 2, 1, 2, 2, 1, 2, 3, 3, 2, 2, 4, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea800b7e",
   "metadata": {},
   "source": [
    "##### Scryfall fetch\n",
    "\n",
    "Below code fetches card data from the Scryfall API, concatenates it into a string, and adds it to the cards_with_data list. Final data is stored in the dataset_df dataframe for tokenization later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "237cc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cards_with_data = []\n",
    "for card in cards:\n",
    "    card_info = predictor.card_utils.get_card_info(card)\n",
    "    with_data = f\"Name: {card_info['name']}\\nMana Cost: {card_info['mana_cost']}\\nTypes: {card_info['types']}\\nOracle Text: {card_info['oracle_text']}\\nPower/Toughness: {card_info['power']}/{card_info['toughness']}\\nLoyalty: {card_info['loyalty']}\\n\\n.\"\n",
    "    cards_with_data.append(with_data)\n",
    "dataset_df = pd.DataFrame({\"card_text\": cards_with_data, \"rating\": ratings})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e75c9d5",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "\n",
    "Tokenizer function that, when passed the data and a tokenizer, will tokenize the inputs for the data and return it. Uses the distilbert tokenizer from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed4301d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize the data for sequence classification\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    \"\"\"Tokenize examples for sequence classification\"\"\"\n",
    "    # Format the examples as input text\n",
    "    texts = [\n",
    "        f\"Rate the Magic: The Gathering card '{card_text}' on a scale from 1 to 5 where 1 is irrelevant to the current standard format and 5 is format-warping.\"\n",
    "        for card_text in examples[\"card_text\"]\n",
    "    ]\n",
    "    \n",
    "    # Tokenize with padding and truncation\n",
    "    tokenized = tokenizer(\n",
    "        texts, \n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Convert ratings to labels (subtract 1 to make labels 0-4 instead of 1-5)\n",
    "    tokenized[\"labels\"] = [label - 1 for label in examples[\"rating\"]]\n",
    "    \n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf77ed2",
   "metadata": {},
   "source": [
    "### Driver Code\n",
    "\n",
    "This is the main driver code that will run all of the functions defined above, and execute fine-tuning of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c5fe4",
   "metadata": {},
   "source": [
    "##### Split into training and test data\n",
    "\n",
    "Using a 80/20 split, split the dataset into training and validation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcc0b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(dataset_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a0c2c6",
   "metadata": {},
   "source": [
    "##### Load model\n",
    "\n",
    "Load the distilbert-base-uncased model from pretrained, load the tokenizer, and declare our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c62a49dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading distilbert/distilbert-base-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "# Make sure the tokenizer has a pad token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "# Load the model with num_labels=5 for the 1-5 rating scale\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=5,  # 5 classes (ratings 1-5)\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50251ce6",
   "metadata": {},
   "source": [
    "##### Create peft config and apply to model\n",
    "\n",
    "Peft is a set of fine-tuning techniques that is aimed to adapt a pre-trained model to a new task while only updating a small amount of parameters. Using peft and LoRA, I can easily train the model on my desktop GPU, and even a laptop CPU should be able to handle training the model using this method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70ba1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,036,805 || all params: 67,994,122 || trainable%: 1.5248\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    inference_mode=False,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,  # Sequence classification task\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"o_lin\"]  # Typical attention modules\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb96e0e",
   "metadata": {},
   "source": [
    "### Training compute power\n",
    "As can be seen above, becuase peft is being pused, the number of parameters that are being trained is being slashed down to less than a 60th of what it would normally be. Because of this optimization, training is trivial to carry out for my desktop GPU, which is an rtx 3070. Even if peft was not being used, because the 3070 has 8 gb of vram, it would be able to load all nearly 68,000,000 parameters into memory quite easily. Distilbert is indeed a very small model, and because of this, training and running it is trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e4921",
   "metadata": {},
   "source": [
    "##### Tokenize the dataset and process into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31fea4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101782d3efe545db85b66ca349abbb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6dd90a7df14d4c97cf082ea8db060d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_dataset(examples):\n",
    "    return tokenize_function(examples, tokenizer)\n",
    "    \n",
    "# Process datasets with batched=True for efficiency\n",
    "tokenized_train = train_dataset.map(\n",
    "    tokenize_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "    \n",
    "tokenized_val = val_dataset.map(\n",
    "    tokenize_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=val_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950386a3",
   "metadata": {},
   "source": [
    "##### Define training arguments and trainer using variables declared above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c86c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    push_to_hub=False,\n",
    "    fp16=False,\n",
    ")\n",
    "   \n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5d864",
   "metadata": {},
   "source": [
    "##### Train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbc63354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.452300</td>\n",
       "      <td>1.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.421100</td>\n",
       "      <td>1.310938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.400800</td>\n",
       "      <td>1.301563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.343800</td>\n",
       "      <td>1.301563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.284400</td>\n",
       "      <td>1.301563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./mtg_rating_model...\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting fine-tuning...\")\n",
    "trainer.train()\n",
    "    \n",
    "# Save the model\n",
    "print(f\"Saving model to {OUTPUT_DIR}...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "        \n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce7230a",
   "metadata": {},
   "source": [
    "### Predict card rating\n",
    "\n",
    "This function predicts the rating for a card when passed the card name, a model, and a tokenizer. It calls the scryfall API for the card data, tokenizes it, passes it to the model, and returns the output as a rating and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62da7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_card_rating(card_name, model, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Predict the rating for a specific Magic: The Gathering card\n",
    "    \n",
    "    Args:\n",
    "        card_name: Name of the card to rate\n",
    "        model: The fine-tuned model\n",
    "        tokenizer: The tokenizer for the model\n",
    "        max_length: Maximum sequence length\n",
    "        \n",
    "    Returns:\n",
    "        rating: Predicted rating (1-5)\n",
    "        confidence: Confidence scores for each class\n",
    "    \"\"\"\n",
    "    # Get card information\n",
    "    try:\n",
    "        card_info = get_card_info(card_name)\n",
    "        card_text = f\"Name: {card_info['name']}\\nMana Cost: {card_info['mana_cost']}\\nTypes: {card_info['types']}\\nOracle Text: {card_info['oracle_text']}\\nPower/Toughness: {card_info['power']}/{card_info['toughness']}\\nLoyalty: {card_info['loyalty']}\\n\\n.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching card info: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Format the prompt as it was during training\n",
    "    prompt = f\"Rate the Magic: The Gathering card '{card_text}' on a scale from 1 to 5 where 1 is irrelevant to the current standard format and 5 is format-warping.\"\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=max_length, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted class and confidence scores\n",
    "    logits = outputs.logits.to(torch.float32)\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)[0]\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    \n",
    "    # Convert back to 1-5 scale (since model was trained on 0-4 labels)\n",
    "    rating = predicted_class + 1\n",
    "    \n",
    "    # Convert probabilities to a regular list\n",
    "    confidence_scores = probabilities.cpu().numpy().tolist()\n",
    "    \n",
    "    return rating, confidence_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1203496",
   "metadata": {},
   "source": [
    "### Run Fine-Tuned Model\n",
    "\n",
    "Here I will pass some example cards to the fine-tuned model to see how it does. The code will call the function above and print the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfd5fe95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card: Abyssal Gorestalker\n",
      "Predicted Rating: 2/5\n",
      "Confidence: ['13.6%', '41.9%', '28.7%', '11.1%', '4.7%']\n",
      "-----------------------\n",
      "Card: Adventuring Gear\n",
      "Predicted Rating: 2/5\n",
      "Confidence: ['13.8%', '41.5%', '28.8%', '11.2%', '4.7%']\n",
      "-----------------------\n",
      "Card: Monstrous Rage\n",
      "Predicted Rating: 2/5\n",
      "Confidence: ['13.5%', '42.0%', '28.7%', '11.2%', '4.6%']\n",
      "-----------------------\n",
      "Card: Phyrexian Arena\n",
      "Predicted Rating: 2/5\n",
      "Confidence: ['13.5%', '42.2%', '28.4%', '11.2%', '4.7%']\n",
      "-----------------------\n",
      "Card: Abrade\n",
      "Predicted Rating: 2/5\n",
      "Confidence: ['13.7%', '41.9%', '28.5%', '11.1%', '4.8%']\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "test_cards = [\"Abyssal Gorestalker\", \"Adventuring Gear\", \"Monstrous Rage\", \"Phyrexian Arena\", \"Abrade\"]\n",
    "\n",
    "for card in test_cards:\n",
    "    rating, confidence = predict_card_rating(card, model, tokenizer)\n",
    "    if rating is not None:\n",
    "        # Format confidence scores as percentages\n",
    "        conf_percentages = [f\"{conf*100:.1f}%\" for conf in confidence]   \n",
    "                 \n",
    "        print(f\"Card: {card}\")\n",
    "        print(f\"Predicted Rating: {rating}/5\")\n",
    "        print(f\"Confidence: {conf_percentages}\")\n",
    "        print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e7d0ed",
   "metadata": {},
   "source": [
    "### Overview:\n",
    "\n",
    "This method failed miserably, for a couple of reasons, both having to do with my data. As we can see, the model has defaulted to predicting 2 for almost every card, with a rare 3, and even though it is doing so, it is doing so without a lot of confidence in that answer. I believe that the reason for this is that the data is skewed towards the lower scores. This is the distribution of the data per score: 1: 17, 2: 36, 3: 34, 4: 11, 5: 2. We can see by looking at the above predictions that the probabilities given for each score \n",
    "\n",
    "Desipte many attempts at modifying hyperparameters such as epochs and learning rate to increase the amount of learning done, I could not bring the model to make different predictions for different cards. The best learning rate that I found was 2e-4. Any lower and the model simply stopped learning anything, and gave near 20 percent for each probability. The model seems to converge after 5 or so epochs each time, if the anti-learning that is being done in a lot of iterations can be called converging. Currently, I firmly believe that the miniscule dataset is preventing the model from learning trends that help it outside of the training data.\n",
    "\n",
    "As a consequence of the very tiny amount of data coupled with the skew, the model is learning to be less surprised that a results is a 2 or a 3 instead of actually learning something about classifying the cards. As a method of evaluating Magic cards, this fine-tuning attempt was a failure. However, as a learning experience about fine-tuning and a lesson in careful and extensive data collection, it was a success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56db04",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### General Results\n",
    "\n",
    "In summary, in the current state of the project, the OpenAI API calling bot works far better than the fine-tuned distilbert model. It is able to rate cards somewhat accurately, even if it often scores them higher than they should be. This is much better than the Fine-tuned model, which ended up rating every card either a 2 or a 3 after fine-tuning. For more detailed analysis of model performace, see each approach's overview cells.\n",
    "\n",
    "### Next steps\n",
    "For the API call, there is not much to change except for more prompt engineering. In it, I would change the prompt to encourage more conservative scores, and only awarding 3s and 4s to higher powered cards. Something interesting to try would be to use RAG to allow the model to learn what is in standard before making it's ratings.\n",
    "\n",
    "For the fine-tuned model, the best thing for me to do to improve performance would be to collect more data, and particularly to even out the distribution of cards/score so that the spread from 1-4 is even. Realistically, there are only ever 2 or 3 5s in the format, and they are self-apparent to anyone to has touched the game, so collecting the data would be impossible unless it was collected from cards outside the standard format, and it would not be necessary for the model to point out 5 powered cards.\n",
    "\n",
    "### What I learned\n",
    "The major lessons that I learned doing this project were that prompt engineering and in context learning are very powerful, and can be used to get admirable results without having to train your own model, and that when attempting to fine-tune a model, data collection is the most important part, and a lot of it is needed to effectively train a model. Additionally, I should have taken much more care in how I selected cards to go in the dataset to avoid getting the skew that I did.\n",
    "\n",
    "### Societal Implications\n",
    "In terms of general society, this model is fairly irrelevant, but in terms of Standard, I would like to run a thought experiment where everyone playing the game has access to my model and uses it (I'll also assume that the model gives good predictions). In this case, the model would predict for them the best cards coming out of a new set and they would go and use them. The problem that would occur in this context is that everyone, assuming that they want to win, would all either be using the same cards, or would be building their decks to answer these best, and now ubiquitous cards. This could lead to a very stale metagame very quickly, and a lot of the fun of deckbuilding and trying out new cards and strategies would be lost. This is one eventuality that I could forsee coming to pass if the scenario that I proposed was true. I believe that if this project was a true success, and the models were quite powerful, Magic the Gathering would suffer as a game because of it, and the Standard format would become a slave to the meta defined by the AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
